# Clasificaci칩n de c치ncer de mama con Random Forest y Optimizaci칩n de Hiperpar치metros
### 游 Objetivo

El objetivo principal de este proyecto es aplicar t칠cnicas de ajuste y optimizaci칩n de hiperpar치metros usando modelos de aprendizaje autom치tico para clasificaci칩n. 

Este proyecto implementa un pipeline de clasificaci칩n usando el conjunto de datos `load_breast_cancer` de `sklearn.datasets`. Se entrenaron y evaluaron tres modelos:

- **Baseline**: Random Forest con hiperpar치metros por defecto.
- **B칰squeda Aleatoria**: Optimizaci칩n de hiperpar치metros con `RandomizedSearchCV`.
- **Optuna**: Optimizaci칩n bayesiana con `Optuna`.

## 游댌 Dataset: Breast Cancer Wisconsin (Diagnostic) Dataset

Este dataset incluye caracter칤sticas computadas a partir de im치genes digitalizadas de tumores mamarios. La variable objetivo es binaria:

- `0`: tumor **benigno**
- `1`: tumor **maligno**

### 游늵 Descripci칩n de las variables

Las variables independientes son todas num칠ricas y representan estad칤sticas b치sicas sobre los n칰cleos celulares de los tumores. Cada variable tiene tres versiones: media (`mean`), error est치ndar (`se`) y valor m치ximo (`worst`). Ejemplos:

| Variable | Descripci칩n |
|----------|-------------|
| `mean radius` | Promedio del radio de los n칰cleos celulares |
| `mean texture` | Desviaci칩n est치ndar de los valores de gris |
| `mean perimeter` | Promedio del per칤metro |
| `mean area` | Promedio del 치rea de los n칰cleos |
| `mean smoothness` | Variaci칩n local en la suavidad de los contornos |
| `...` | ... se repite para `se` y `worst` en todas las variables anteriores |

Hay un total de **30 caracter칤sticas num칠ricas** derivadas de las im치genes m칠dicas.

---

## 游늵 Mini An치lisis Exploratorio de Datos (EDA)

- N칰mero de instancias: 569
- N칰mero de variables (caracter칤sticas): 30
- Clases objetivo: `0 = Maligno`, `1 = Benigno`
- Las caracter칤sticas est치n escaladas antes del entrenamiento.
- Se aplic칩 **reducci칩n de dimensionalidad (PCA)** a 10 componentes principales, reteniendo m치s del 95% de la varianza.


## 游늳 Resultados

| Modelo             | ROC AUC (Entrenamiento) | ROC AUC (Test) |
|--------------------|--------------------------|----------------|
| Baseline           | 0.987461                 | 0.993882       |
| B칰squeda Aleatoria | 0.988545                 | 0.992063       |
| Optuna             | 0.989680                 | 0.992394       |

> 游댌 El modelo **Baseline** obtuvo el mejor desempe침o en el conjunto de prueba, aunque los tres modelos presentaron resultados sobresalientes.

## 游늷 Conclusiones

- Los tres modelos superaron el 98% en AUC, lo que indica un excelente poder predictivo.
- La b칰squeda de hiperpar치metros no siempre garantiza una mejora en test; en este caso, el modelo base fue el mejor en ese conjunto.
- Optuna fue el modelo m치s eficiente en validaci칩n cruzada, lo cual sugiere un mejor desempe침o generalizable.

## 游닍 Librer칤as utilizadas

- `pandas`, `numpy`, `matplotlib`, `seaborn`
- `sklearn` (para modelos, m칠tricas, validaci칩n)
- `optuna` (optimizaci칩n bayesiana)

---
## 游녻 Autor

**Nombre:** Manuela Botero Buitrago  
